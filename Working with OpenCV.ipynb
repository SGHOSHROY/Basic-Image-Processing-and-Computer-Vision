{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b81433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d840bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"istockphoto-182848692-612x612.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066e3d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a solid color test image\n",
    "test_img = np.zeros((300, 400, 3), dtype=np.uint8)  # 400x300 black image\n",
    "test_img[:] = (0, 255, 0)  # Make it green\n",
    "\n",
    "cv2.imshow(\"Test Image\", test_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a24215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.path.exists(\"istockphoto-182848692-612x612.jpg\"))  # Should return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0aefa",
   "metadata": {},
   "source": [
    "### For Displaying image in Google Colab\n",
    "\n",
    "<p>cv2.imshow() is a disabled function in Colab because it can cause the Jupyter session to crash. Google Colab provides a specific function, cv2_imshow, for displaying images within the notebook.</p>\n",
    "\n",
    "<code>from google.colab.patches import cv2_imshow \n",
    "cv2_imshow(test_img)</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cfdfde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"window1\",img)\n",
    "cv2.waitKey(0) ## Induces an infinite delay, so that window never closes until the user does returning -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca8ea693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0   2   2]\n",
      "  [  0   2   2]\n",
      "  [  0   2   2]\n",
      "  ...\n",
      "  [ 21 135 255]\n",
      "  [  7 144 255]\n",
      "  [  0 136 255]]\n",
      "\n",
      " [[  0   2   2]\n",
      "  [  0   2   2]\n",
      "  [  0   2   2]\n",
      "  ...\n",
      "  [ 14 140 255]\n",
      "  [  5 146 255]\n",
      "  [  0 129 241]]\n",
      "\n",
      " [[  0   2   2]\n",
      "  [  0   2   2]\n",
      "  [  0   2   2]\n",
      "  ...\n",
      "  [  0 123 235]\n",
      "  [  0 122 211]\n",
      "  [  0  97 183]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[156 128  93]\n",
      "  [156 128  93]\n",
      "  [157 129  94]\n",
      "  ...\n",
      "  [ 41  51  58]\n",
      "  [ 42  52  59]\n",
      "  [ 43  53  60]]\n",
      "\n",
      " [[150 122  87]\n",
      "  [149 121  86]\n",
      "  [150 122  87]\n",
      "  ...\n",
      "  [ 43  52  62]\n",
      "  [ 44  53  63]\n",
      "  [ 45  54  64]]\n",
      "\n",
      " [[141 117  81]\n",
      "  [140 116  80]\n",
      "  [141 117  81]\n",
      "  ...\n",
      "  [ 43  50  67]\n",
      "  [ 45  52  69]\n",
      "  [ 47  54  71]]]\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f070796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d504c56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(407, 612, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d47245f",
   "metadata": {},
   "source": [
    "### How to convert into grayscale\n",
    "\n",
    "- cv2.cvtColor(): This function from the OpenCV library is used to convert images from one color space to another.\n",
    "</br></br>\n",
    "- img: This is the input image, typically loaded using cv2.imread(). By default, OpenCV reads images in BGR (Blue, Green, Red) format.\n",
    "</br></br>\n",
    "- cv2.COLOR_BGR2GRAY: This is a flag that tells OpenCV to convert the image from BGR color space to Grayscale. In Grayscale images, each pixel represents intensity, ranging from black (0) to white (255).\n",
    "</br></br>\n",
    "- grayscale: This is the resulting image after conversion. It's a single-channel image where each pixel denotes the intensity of light.\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1e95476",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f016329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"grayscale_window\",grayscale)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eacbbb",
   "metadata": {},
   "source": [
    "- Unlike, previous, we have have only one channel, instead of three different channels for Red, Green and Blue. So, the third value from the tuple is ommitted out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5738c7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(407, 612)\n"
     ]
    }
   ],
   "source": [
    "print(grayscale.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc64b8",
   "metadata": {},
   "source": [
    "## **Playing with RGB Color Channels**\n",
    "\n",
    "IMAGE[Dimension1,Dimension2,COLOR_CHANNEL]\n",
    "\n",
    "<code> blue = image[:,:,0] </code></br>\n",
    "<code> green = image[:,:,1] </code></br>\n",
    "<code> red = image[:,:,2] </code></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fad452b",
   "metadata": {},
   "source": [
    "### **Making The Blue Component Zero**\n",
    "\n",
    "• The code removes the blue component from a 3D numpy array representing an image\n",
    "\n",
    "• The resulting image has only green and red channels, leading to a yellowish shade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d36c69e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowers = cv2.imread(\"istockphoto-182848692-612x612.jpg\")\n",
    "## Making the Blue component to zero\n",
    "flowers[:,:,0]=0\n",
    "cv2.imshow(\"zero_blue\",flowers)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ebc326",
   "metadata": {},
   "source": [
    "### **Making The Green Component Zero**\n",
    "\n",
    "• The code removes the green component from a 3D numpy array representing an image\n",
    "\n",
    "• The resulting image has only blue and red channels, leading to a purple shade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e2f47a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowers = cv2.imread(\"istockphoto-182848692-612x612.jpg\")\n",
    "## Making the Green component to zero\n",
    "flowers[:,:,1]=0\n",
    "cv2.imshow(\"zero_green\",flowers)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1588b26d",
   "metadata": {},
   "source": [
    "### **Making The Red Component Zero**\n",
    "\n",
    "• The code removes the red component from a 3D numpy array representing an image\n",
    "\n",
    "• The resulting image has only green and blue channels in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c475f1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowers = cv2.imread(\"istockphoto-182848692-612x612.jpg\")\n",
    "## Making the Red component to zero\n",
    "flowers[:,:,2]=0\n",
    "cv2.imshow(\"zero_red\",flowers)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20621aa",
   "metadata": {},
   "source": [
    "### **Showing The Red Component only**\n",
    "\n",
    "• The code displays the red component from a 3D numpy array representing an image\n",
    "\n",
    "• The resulting image has only red channels, making green and blue components = zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1205235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowers = cv2.imread(\"istockphoto-182848692-612x612.jpg\")\n",
    "## Red component\n",
    "flowers[:,:,0]=0\n",
    "flowers[:,:,1]=0\n",
    "cv2.imshow(\"only_red\",flowers)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab3cbb",
   "metadata": {},
   "source": [
    "### **Showing The Blue Component only**\n",
    "\n",
    "• The code displays the blue component from a 3D numpy array representing an image\n",
    "\n",
    "• The resulting image has only blue channels, making green and red components = zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73a5b289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowers = cv2.imread(\"istockphoto-182848692-612x612.jpg\")\n",
    "## Blue component\n",
    "flowers[:,:,1]=0\n",
    "flowers[:,:,2]=0\n",
    "cv2.imshow(\"only_blue\",flowers)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53c1a99",
   "metadata": {},
   "source": [
    "### **Showing The Green Component only**\n",
    "\n",
    "• The code displays the green component from a 3D numpy array representing an image\n",
    "\n",
    "• The resulting image has only green channels, making red and blue components = zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "636ff23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowers = cv2.imread(\"istockphoto-182848692-612x612.jpg\")\n",
    "## Green component\n",
    "flowers[:,:,0]=0\n",
    "flowers[:,:,2]=0\n",
    "cv2.imshow(\"only_green\",flowers)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73f64962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowers = cv2.imread(\"istockphoto-182848692-612x612.jpg\")\n",
    "## Maximum Blue Component\n",
    "flowers[:,:,0]=255\n",
    "cv2.imshow(\"Max_blue\",flowers)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5709cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowers = cv2.imread(\"istockphoto-182848692-612x612.jpg\")\n",
    "## Maximum Green Component\n",
    "flowers[:,:,1]=255\n",
    "cv2.imshow(\"Max_green\",flowers)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95f3214d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowers = cv2.imread(\"istockphoto-182848692-612x612.jpg\")\n",
    "## Maximum Green Component\n",
    "flowers[:,:,2]=255\n",
    "cv2.imshow(\"Max_red\",flowers)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a680e",
   "metadata": {},
   "source": [
    "### **How To Stack Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d8c64bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgRed = cv2.imread(\"istockphoto-182848692-612x612.jpg\") ## For displaying Red Component\n",
    "imgBlue = cv2.imread(\"istockphoto-182848692-612x612.jpg\") ## For displaying Blue Component\n",
    "imgGreen = cv2.imread(\"istockphoto-182848692-612x612.jpg\") ## For displaying Green Component\n",
    "## Making the Blue and Green component to zero\n",
    "imgRed[:,:,0]=0\n",
    "imgRed[:,:,1]=0\n",
    "## Making the Red and Green component to zero\n",
    "imgBlue[:,:,1]=0\n",
    "imgBlue[:,:,2]=0\n",
    "## Making the Red and Blue component to zero\n",
    "imgGreen[:,:,0]=0\n",
    "imgGreen[:,:,2]=0\n",
    "new_img = np.hstack((imgBlue,imgRed,imgGreen))\n",
    "cv2.imshow(\"New Image\",new_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0b55545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgwithoutRed = cv2.imread(\"istockphoto-182848692-612x612.jpg\") ## For displaying Red Component\n",
    "imgwithoutblue = cv2.imread(\"istockphoto-182848692-612x612.jpg\") ## For displaying Blue Component\n",
    "imgwithoutgreen = cv2.imread(\"istockphoto-182848692-612x612.jpg\") ## For displaying Green Component\n",
    "## Making the Blue component to zero\n",
    "imgwithoutblue[:,:,0]=0\n",
    "## Making the Green component to zero\n",
    "imgwithoutgreen[:,:,1]=0\n",
    "## Making the Red component to zero\n",
    "imgwithoutRed[:,:,2]=0\n",
    "new_img = np.hstack((imgwithoutblue,imgwithoutgreen,imgwithoutRed))\n",
    "cv2.imshow(\"New Image\",new_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "addbcf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgmaxRed = cv2.imread(\"istockphoto-182848692-612x612.jpg\") ## For displaying Red Component\n",
    "imgmaxblue = cv2.imread(\"istockphoto-182848692-612x612.jpg\") ## For displaying Blue Component\n",
    "imgmaxgreen = cv2.imread(\"istockphoto-182848692-612x612.jpg\") ## For displaying Green Component\n",
    "## Making the Blue component to zero\n",
    "imgmaxblue[:,:,0]=255\n",
    "## Making the Green component to zero\n",
    "imgmaxgreen[:,:,1]=255\n",
    "## Making the Red component to zero\n",
    "imgmaxRed[:,:,2]=255\n",
    "new_img = np.hstack((imgmaxblue,imgmaxgreen,imgmaxRed))\n",
    "cv2.imshow(\"New Image\",new_img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1b11c",
   "metadata": {},
   "source": [
    "### Image Resize\n",
    "- <code> cv2.resize(img,dimension_tuple(256,256,3)) </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "196e54db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Image Resize\n",
    "img_resize = cv2.resize(img,(256,256))\n",
    "## Display the image\n",
    "cv2.imshow(\"Image Resized\",img_resize)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c780f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img_resize.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "938b5e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Image Resize\n",
    "img_resize_to_half = cv2.resize(img,(img.shape[1]//2,img.shape[0]//2))\n",
    "## OpenCV takes second index dimension of its shape first followed by the first so img.shape[1] first followed by img.shape[0]\n",
    "## Display the image\n",
    "cv2.imshow(\"Half Resized Image\",img_resize_to_half)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa51b4ac",
   "metadata": {},
   "source": [
    "### Flipping an Image\n",
    "\n",
    "- <code>cv2.flip(Image,flip_code) #flip_code = {0,1,-1}</code>\n",
    "</br></br>\n",
    "- Flipping is used in Data Augmentation and creating new datasets for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb3215d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_flip = cv2.flip(img,0) #Verical flip\n",
    "img_stack = np.hstack((img,img_flip))\n",
    "cv2.imshow(\"Flipped Image\",img_stack)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "12c60761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_flip = cv2.flip(img,1) #Horizontal flip\n",
    "img_stack = np.vstack((img,img_flip))\n",
    "cv2.imshow(\"Flipped Image\",img_stack)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "348f1984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_flip = cv2.flip(img,-1) #Horizontal + Verical flip\n",
    "img_stack = np.vstack((img,img_flip))\n",
    "cv2.imshow(\"Flipped Image\",img_stack)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70d04b9",
   "metadata": {},
   "source": [
    "### Cropping An Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9c2ff940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_crop = img[100:300,200:500]\n",
    "cv2.imshow(\"Cropped Image\",img_crop)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c448f0",
   "metadata": {},
   "source": [
    "### Saving An Image\n",
    "\n",
    "- <Code>cv2.imwrite(\"{{Name of the file to be saved}}\",image)</Code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46209623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"Flowers.jpg\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c897fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_flip_1 = cv2.flip(img,1) #Horizontal flip\n",
    "img_stack_1 = np.hstack((img,img_flip_1))\n",
    "img_flip_2 = cv2.flip(img,0) #Verical flip\n",
    "img_flip_3 = cv2.flip(img,-1) #Horizontal + Verical flip\n",
    "img_stack_2 = np.hstack((img_flip_2,img_flip_3))\n",
    "img_stack = np.vstack((img_stack_1,img_stack_2))\n",
    "cv2.imwrite(\"Flowers_mirror.jpg\",img_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e7192",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
